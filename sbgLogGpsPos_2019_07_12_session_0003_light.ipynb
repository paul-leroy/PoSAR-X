{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/pleroy/DATA/PoSAR-X/PIMA-1/2019_07_12/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/pleroy/DEV/processing/PoSAR-MC\")\n",
    "from posarmctools.ekfnavtools import *\n",
    "import posarmctools.epsgtools as epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/pleroy/DEV/processing/focalization_python\")\n",
    "from posarutils.other.PosarMCParameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "withPlots = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPSG transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some common projections using EPSG codes\n",
    "wgs84 = pyproj.Proj(\"+init=EPSG:4326\")      # LatLon with WGS84 datum used by GPS units and Google Earth\n",
    "epsg3857 = pyproj.Proj(\"+init=EPSG:3857\")   # WGS84 / Pseudo Mercator\n",
    "epsg3395 = pyproj.Proj(\"+init=EPSG:3395\")   # WGS84 / World Mercator\n",
    "epsg3948 = pyproj.Proj(\"+init=EPSG:3948\")   # RGF93 / CC48 Projected coordinate system\n",
    "epsg32630 = pyproj.Proj(\"+init=EPSG:32630\") # WGS 84 / UTM zone 30N\n",
    "\n",
    "epsg3xxx = epsg32630 # epsg3857 does not seem to keep distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if epsg3xxx == epsg3857:\n",
    "    epsgStr = \"epsg3857\"\n",
    "    \n",
    "if epsg3xxx == epsg3948:\n",
    "    epsgStr = \"epsg3948\"\n",
    "    \n",
    "if epsg3xxx == epsg32630:\n",
    "    epsgStr = \"epsg32630\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene remarkable points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner = [ 48 + 03.462/60, -( 2 + 00.507/60 ) ]\n",
    "corner_epsg = epsg.wgs84ToEpsg( corner[::-1], epsg3xxx )\n",
    "\n",
    "h0 = [ 48 + 03.409/60, -( 2 + 00.468/60 ) ]\n",
    "h1 = [ 48 + 03.409/60, -( 2 + 00.481/60 ) ]\n",
    "h2 = [ 48 + 03.401/60, -( 2 + 00.479/60 ) ]\n",
    "h3 = [ 48 + 03.401/60, -( 2 + 00.467/60 ) ]\n",
    "h0_epsg = epsg.wgs84ToEpsg( h0[::-1], epsg3xxx )\n",
    "h1_epsg = epsg.wgs84ToEpsg( h1[::-1], epsg3xxx )\n",
    "h2_epsg = epsg.wgs84ToEpsg( h2[::-1], epsg3xxx )\n",
    "h3_epsg = epsg.wgs84ToEpsg( h3[::-1], epsg3xxx )\n",
    "\n",
    "p0 = [ 48 + 03.453/60, -( 2 + 00.629/60 ) ]\n",
    "p1 = [ 48 + 03.440/60, -( 2 + 00.624/60 ) ]\n",
    "p2 = [ 48 + 03.504/60, -( 2 + 00.358/60 ) ]\n",
    "p3 = [ 48 + 03.491/60, -( 2 + 00.353/60 ) ]\n",
    "p0_epsg = epsg.wgs84ToEpsg( p0[::-1], epsg3xxx )\n",
    "p1_epsg = epsg.wgs84ToEpsg( p1[::-1], epsg3xxx )\n",
    "p2_epsg = epsg.wgs84ToEpsg( p2[::-1], epsg3xxx )\n",
    "p3_epsg = epsg.wgs84ToEpsg( p3[::-1], epsg3xxx )\n",
    "\n",
    "s0 = [ 48 + 03.649/60, -( 1 + 59.701/60 ) ] # 82 m\n",
    "s1 = [ 48 + 03.650/60, -( 2 + 01.313/60 ) ] # 98 m\n",
    "s2 = [ 48 + 03.274/60, -( 2 + 01.354/60 ) ] # 107 m\n",
    "s3 = [ 48 + 03.275/60, -( 1 + 59.725/60 ) ] # 84 m\n",
    "s4 = [ 48 + 04.003/60, -( 2 + 00.793/60 ) ] # 96 m\n",
    "s5 = [ 48 + 02.940/60, -( 2 + 00.793/60 ) ] # 77 m\n",
    "s6 = [ 48 + 02.916/60, -( 2 + 00.228/60 ) ] # 83 m\n",
    "s7 = [ 48 + 04.015/60, -( 2 + 00.226/60 ) ] # 91 m\n",
    "\n",
    "s0_epsg = epsg.wgs84ToEpsg( s0[::-1], epsg3xxx )\n",
    "s1_epsg = epsg.wgs84ToEpsg( s1[::-1], epsg3xxx )\n",
    "s2_epsg = epsg.wgs84ToEpsg( s2[::-1], epsg3xxx )\n",
    "s3_epsg = epsg.wgs84ToEpsg( s3[::-1], epsg3xxx )\n",
    "s4_epsg = epsg.wgs84ToEpsg( s4[::-1], epsg3xxx )\n",
    "s5_epsg = epsg.wgs84ToEpsg( s5[::-1], epsg3xxx )\n",
    "s6_epsg = epsg.wgs84ToEpsg( s6[::-1], epsg3xxx )\n",
    "s7_epsg = epsg.wgs84ToEpsg( s7[::-1], epsg3xxx )\n",
    "\n",
    "x0 = [ 48 + 03.661/60, -( 1 + 58.893/60 ) ]\n",
    "x1 = [ 48 + 03.647/60, -( 2 + 02.121/60 ) ]\n",
    "x2 = [ 48 + 03.273/60, -( 2 + 02.141/60 ) ]\n",
    "x3 = [ 48 + 03.278/60, -( 1 + 58.933/60 ) ]\n",
    "x4 = [ 48 + 04.572/60, -( 2 + 00.798/60 ) ]\n",
    "x5 = [ 48 + 02.410/60, -( 2 + 00.795/60 ) ]\n",
    "x6 = [ 48 + 02.394/60, -( 2 + 00.226/60 ) ]\n",
    "x7 = [ 48 + 04.558/60, -( 2 + 00.229/60 ) ]\n",
    "\n",
    "np.save( f\"{root_dir}corner_epsg\", corner_epsg )\n",
    "np.save( f\"{root_dir}hangar_epsg\", (h0_epsg, h1_epsg, h2_epsg, h3_epsg) )\n",
    "np.save( f\"{root_dir}runaway_epsg\", (p0_epsg, p1_epsg, p2_epsg, p3_epsg))\n",
    "np.save( f\"{root_dir}s_epsg\", (s0_epsg, s1_epsg, s2_epsg, s3_epsg, s4_epsg, s5_epsg, s6_epsg, s7_epsg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRemarkablePoints( ax ):\n",
    "    ax.plot( s0_epsg[0], s0_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s1_epsg[0], s1_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s2_epsg[0], s2_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s3_epsg[0], s3_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s4_epsg[0], s4_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s5_epsg[0], s5_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s6_epsg[0], s6_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( s7_epsg[0], s7_epsg[1], 'oy', markeredgecolor = 'black' )\n",
    "    ax.plot( corner_epsg[0], corner_epsg[1], 'og', markeredgecolor = 'black' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data path definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = \"2019_07_12\"\n",
    "prefix = \"/home/pleroy/DATA/PoSAR-X/PIMA-1/2019_07_12_SBG/session_0003/\" + day + \"/\"\n",
    "\n",
    "hours = [\"11h00\", \"12h00\"]\n",
    "nbHours = len(hours)\n",
    "\n",
    "logEkfEuler = [ prefix + h + \"/sbgLogEkfEuler.dat\" for h in hours ]\n",
    "logEkfNav  = [ prefix + h + \"/sbgLogEkfNav.dat\" for h in hours ]\n",
    "logUtcData = [ prefix + h + \"/sbgLogUtcData.dat\" for h in hours ]\n",
    "logGpsPos = [ prefix + h + \"/sbgLogGpsPos.csv\" for h in hours ]\n",
    "logGpsVel = [ prefix + h + \"/sbgLogGpsVel.dat\" for h in hours ]\n",
    "logEventB = [ prefix + h + \"/sbgLogEventB.dat\" for h in hours ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  logGpsPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_gpsPos_status = 1\n",
    "idx_gpsPos_lat = 3\n",
    "idx_gpsPos_long = 4\n",
    "idx_gpsPos_alt = 5\n",
    "idx_gpsPos_undulation = 6\n",
    "idx_gps_lat = 1\n",
    "idx_gps_long = 2\n",
    "idx_gps_alt = 3\n",
    "idx_gps_undulation = 4\n",
    "idx_gps_status = 5\n",
    "\n",
    "def loadLogGpsPos( gps, n ):\n",
    "    for idx in range(n):\n",
    "        gps.append( np.loadtxt( logGpsPos[idx], skiprows = 1, delimiter = ',',\n",
    "                               usecols = (0, idx_gpsPos_lat, idx_gpsPos_long, idx_gpsPos_alt, idx_gpsPos_undulation,\n",
    "                                         idx_gpsPos_status) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps=[]\n",
    "loadLogGpsPos( gps, nbHours )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_all = gps[0]\n",
    "for idx in range(1, 2):\n",
    "    gps_all = np.concatenate( (gps_all, gps[idx]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsTimestamps = gps_all[:, 0]\n",
    "Lat = gps_all[:,idx_gps_lat]\n",
    "Long = gps_all[:,idx_gps_long]\n",
    "Alt = gps_all[:,idx_gps_alt]\n",
    "Undulation = gps_all[:,idx_gps_undulation]\n",
    "gpsPos_status = gps_all[:,idx_gps_alt].astype(\"uint32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "posStatus = np.zeros( gpsPos_status.shape )\n",
    "posType = np.zeros( gpsPos_status.shape )\n",
    "for idx, val in enumerate(gpsPos_status):\n",
    "    posStatus[idx] = val & 0b000011\n",
    "    posType[idx] = np.right_shift( (val & 0b111111000000), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,gpsTimestamps.shape[0]):\n",
    "    if gpsTimestamps[k] < gpsTimestamps[k-1]:\n",
    "        print(\"k = {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsNewTimestamps = gpsTimestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lat = 1\n",
    "idx_long = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "x0, y0 = epsg.wgs84ToEpsg( (gps[idx][:,idx_long], gps[idx][:,idx_lat]), epsg3xxx )\n",
    "\n",
    "idx = 1\n",
    "x1, y1 = epsg.wgs84ToEpsg( (gps[idx][:,idx_long], gps[idx][:,idx_lat]), epsg3xxx )\n",
    "\n",
    "x = [x0, x1]\n",
    "y = [y0, y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_proj = epsg.wgs84ToEpsg( (Long, Lat), epsg3xxx )\n",
    "np.save( root_dir + \"gps_epsg_transform\", gps_proj )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logGpsVel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_gpsVel_status = 1\n",
    "idx_gpsVel_north = 3\n",
    "idx_gpsVel_east = 4\n",
    "idx_gpsVel_down = 5\n",
    "idx_gpsVel_course = 9\n",
    "\n",
    "vel=[]\n",
    "for idx in range(nbHours):\n",
    "    vel.append( np.loadtxt( logGpsVel[idx], skiprows = 1,\n",
    "                           usecols = (0, idx_gpsVel_north, idx_gpsVel_east, idx_gpsVel_down, \n",
    "                                      idx_gpsVel_course, idx_gpsVel_status) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_all = vel[0]\n",
    "for idx in range(1, nbHours):\n",
    "    vel_all = np.concatenate( (vel_all, vel[idx]), axis=0 )\n",
    "velNorth = vel_all[:,1]\n",
    "velEast = vel_all[:,2]\n",
    "velDown = vel_all[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vel = ( velNorth**2 + velEast**2 + velDown**2) **0.5\n",
    "course = vel_all[:,4]\n",
    "velTimestamps = vel_all[:,0]\n",
    "gpsVel_status = vel_all[:,5].astype(\"uint32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sbgLogEventB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = []\n",
    "for idx in range(nbHours):\n",
    "    event.append( np.loadtxt( logEventB[idx], skiprows = 1, usecols = 0 ) )\n",
    "\n",
    "indexes = []\n",
    "indexes.append( np.arange(event[0].size) )\n",
    "for idx in range(1, nbHours):\n",
    "    indexes.append( np.arange(event[idx].size)+indexes[idx-1][-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if event[0].size == 1:\n",
    "    event_all = np.array([event[0]])\n",
    "else:\n",
    "    event_all = event[0]\n",
    "for idx in range(1, nbHours):\n",
    "    event_all = np.concatenate( (event_all, event[idx]), axis=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logUtcData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeStamp status year month day hour minute second nanoSecond gpsTimeOfWeek\n",
    "idx_h = 5\n",
    "idx_m = 6\n",
    "idx_s = 7\n",
    "idx_nano = 8\n",
    "\n",
    "utc = []\n",
    "for idx in range(nbHours):\n",
    "    utc.append( np.loadtxt( logUtcData[idx], skiprows = 1, usecols = (0, idx_h, idx_m, idx_s, idx_nano) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_all = utc[0]\n",
    "for idx in range(1, nbHours):\n",
    "    utc_all = np.concatenate( (utc_all, utc[idx]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 6.0 : 56.525\n",
      "11.0 : 52.0 : 32.010\n",
      "12.0 : 35.0 : 46.905\n"
     ]
    }
   ],
   "source": [
    "printUtc( 0, utc_all )\n",
    "printUtc( 1, utc_all )\n",
    "printUtc( -1, utc_all )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "utcTimestamps = utc_all[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,utcTimestamps.shape[0]):\n",
    "    if utcTimestamps[k] < utcTimestamps[k-1]:\n",
    "        print(\"k = {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "utcNewTimestamps = utcTimestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    plt.figure()\n",
    "    plt.plot( utcNewTimestamps, 'o' )\n",
    "    plt.plot( utcTimestamps,'.' )\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 6.0 : 56.525\n",
      "11.0 : 52.0 : 32.010\n",
      "12.0 : 35.0 : 46.905\n"
     ]
    }
   ],
   "source": [
    "printUtc( 0, utc_all )\n",
    "printUtc( 1, utc_all )\n",
    "printUtc( -1, utc_all )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logEkfEuler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_timeStamp = 0\n",
    "idx_roll = 1\n",
    "idx_pitch = 2\n",
    "idx_yaw = 3\n",
    "idx_rollStdDev = 4\n",
    "idx_pitchStdDev = 5\n",
    "idx_yawStdDev = 6\n",
    "idx_status = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler = []\n",
    "for idx in range(nbHours):\n",
    "    euler.append( np.loadtxt( logEkfEuler[idx], skiprows = 1,\n",
    "                             usecols = (0, idx_roll, idx_pitch, idx_yaw) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_all = euler[0]\n",
    "for idx in range(1, nbHours):\n",
    "    euler_all = np.concatenate( (euler_all, euler[idx]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eulerTimestamps = euler_all[:,0]\n",
    "roll = euler_all[:,1]\n",
    "pitch = euler_all[:,2]\n",
    "yaw = euler_all[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,eulerTimestamps.shape[0]):\n",
    "    if eulerTimestamps[k] < eulerTimestamps[k-1]:\n",
    "        print(\"k = {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eulerNewTimestamps = eulerTimestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logEkfNav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_timeStamp = 0\n",
    "idx_velNorth = 1\n",
    "idx_velEast = 2\n",
    "idx_velDown = 3\n",
    "idx_velNorth_StdDev = 4\n",
    "idx_velEast_StdDev = 5\n",
    "idx_velDown_StdDev = 6\n",
    "idx_ekf_Lat = 7\n",
    "idx_ekf_Long = 8\n",
    "idx_ekf_Alt = 9\n",
    "idx_ekf_undulation = 10\n",
    "idx_ekf_Lat_StdDev = 11\n",
    "idx_ekf_Long_StdDev = 12\n",
    "idx_ekf_Alt_StdDev = 13\n",
    "idx_status = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = []\n",
    "for idx in range(nbHours):\n",
    "    nav.append( np.loadtxt( logEkfNav[idx], skiprows = 1,\n",
    "                           usecols = (0, idx_ekf_Lat, idx_ekf_Long, idx_ekf_Alt, idx_ekf_undulation, idx_status) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_all = nav[0]\n",
    "for idx in range(1, nbHours):\n",
    "    nav_all = np.concatenate( (nav_all, nav[idx]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "navTimestamps = nav_all[:,0]\n",
    "nav_Lat = nav_all[:,1]\n",
    "nav_Long = nav_all[:,2]\n",
    "nav_Alt = nav_all[:,3]\n",
    "nav_Undulation = nav_all[:,4]\n",
    "nav_status = nav_all[:,5].astype(\"uint32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_mode = np.zeros( nav_status.shape )\n",
    "for idx, val in enumerate(nav_status):\n",
    "    solution_mode[idx] = val & 0b1111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,navTimestamps.shape[0]):\n",
    "    if navTimestamps[k] < navTimestamps[k-1]:\n",
    "        print(\"k = {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "navNewTimestamps = navTimestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform EKF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_proj = epsg.wgs84ToEpsg( (nav_Long, nav_Lat), epsg3xxx )\n",
    "np.save( root_dir + \"nav_epsg_transform\", nav_proj )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoSAR-MC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"14_12_21\", \"14_14_43\", \"14_18_28\", \"14_21_00\"]\n",
    "\n",
    "data_date = [ f\"{day}_\" + d for d in dates ]\n",
    "data_dir = [root_dir +  d for d in data_date]\n",
    "\n",
    "firstRecord = 0\n",
    "lastRecord = [116, 110, 92, 126]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process timeStamps.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTimestamps(idx, dropFirst=0, withPlot=1):\n",
    "    \n",
    "    #====================================================================\n",
    "    # the last value of the file may be erroneous, this should be checked\n",
    "    #====================================================================\n",
    "\n",
    "    #===================================================================\n",
    "    # the first value may be erroneous, one may have to shift all values\n",
    "    #===================================================================\n",
    "    \n",
    "    timeStampsFile = data_dir[idx] + \"/\" + data_date[idx] + \"_timeStamps.data\"\n",
    "    print(timeStampsFile)\n",
    "    bufferNumber, timeStamp = np.loadtxt( timeStampsFile, skiprows = 1, unpack=True )\n",
    "\n",
    "    if dropFirst:\n",
    "        bufferNumber = bufferNumber[:-1]\n",
    "        timeStamp = timeStamp[1:]\n",
    "    \n",
    "    if withPlot:\n",
    "        plt.figure()\n",
    "        plt.subplot(211)\n",
    "        plt.plot( timeStamp, \".\", label=data_date[idx] )\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(\"timeStamp wrt fileNumber / \" + data_date[idx] )\n",
    "        plt.subplot(212)\n",
    "        plt.plot( np.diff(timeStamp)/1e6, \".\" )\n",
    "        plt.grid()\n",
    "        plt.title( \"diff(timeStamp) wrt fileNumber / \" + data_date[idx] )\n",
    "    \n",
    "    return bufferNumber, timeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bufferNumber = {}\n",
    "timeStamp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pleroy/DATA/PoSAR-X/PIMA-1/2019_07_12/2019_07_12_14_12_21/2019_07_12_14_12_21_timeStamps.data\n"
     ]
    }
   ],
   "source": [
    "rec = 0\n",
    "dropFirst=0\n",
    "withPlot=0\n",
    "bufferNumber[rec], timeStamp[rec] = checkTimestamps(rec, dropFirst, withPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pleroy/DATA/PoSAR-X/PIMA-1/2019_07_12/2019_07_12_14_14_43/2019_07_12_14_14_43_timeStamps.data\n"
     ]
    }
   ],
   "source": [
    "rec = 1\n",
    "dropFirst=0\n",
    "withPlot=0\n",
    "bufferNumber[rec], timeStamp[rec] = checkTimestamps(rec, dropFirst, withPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pleroy/DATA/PoSAR-X/PIMA-1/2019_07_12/2019_07_12_14_18_28/2019_07_12_14_18_28_timeStamps.data\n"
     ]
    }
   ],
   "source": [
    "rec = 2\n",
    "dropFirst=0\n",
    "withPlot=0\n",
    "bufferNumber[rec], timeStamp[rec] = checkTimestamps(rec, dropFirst, withPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pleroy/DATA/PoSAR-X/PIMA-1/2019_07_12/2019_07_12_14_21_00/2019_07_12_14_21_00_timeStamps.data\n"
     ]
    }
   ],
   "source": [
    "rec = 3\n",
    "dropFirst=0\n",
    "withPlot=0\n",
    "bufferNumber[rec], timeStamp[rec] = checkTimestamps(rec, dropFirst, withPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be carefull here, there could be a jump in the timeStamp values due to the counter saturation at 2^32. The mitigation is following.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestampsShift = {}\n",
    "timestampsShift[0] = 0 # this is for the SBG internal us loopback\n",
    "timestampsShift[1] = 0\n",
    "timestampsShift[2] = 0\n",
    "timestampsShift[3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTimeStamp = {}\n",
    "for rec in timeStamp:\n",
    "    newTimeStamp[rec] = timeStamp[rec] + timestampsShift[rec] * 2**32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 : 12.0 : 12.715\n",
      "12.0 : 14.0 : 32.640\n",
      "12.0 : 18.0 : 19.205\n",
      "12.0 : 20.0 : 49.440\n"
     ]
    }
   ],
   "source": [
    "for rec in newTimeStamp:\n",
    "    printUtc( np.where(utcNewTimestamps < newTimeStamp[rec][0])[0][-1], utc_all )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedRecord = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxTmp = np.where(event_all == timeStamp[selectedRecord][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_filename = data_dir[selectedRecord] + \"/\" + data_date[selectedRecord] + \"_parameters.xml\"\n",
    "params = PosarXParameters( params_filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNbRecords( first, last, params ):\n",
    "    nbRecords = [int((l - first) / params.buffersPerFile + 1) for l in last]\n",
    "    return nbRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbRecords = [59, 56, 47, 64]\n",
      "selectedRecord 1 => 56 files\n"
     ]
    }
   ],
   "source": [
    "samplesPerRamp = params.samplesPerRamp\n",
    "rampsPerFile = params.rampsPerFile\n",
    "rampsPerBuffer = params.rampsPerBuffer\n",
    "samplesPerFile = params.samplesPerRamp * params.rampsPerFile\n",
    "buffersPerFile = params.buffersPerFile\n",
    "T_files = samplesPerFile / 10e6\n",
    "\n",
    "nbRecords = getNbRecords(firstRecord, lastRecord, params)\n",
    "\n",
    "print( \"nbRecords = {}\".format(nbRecords) )\n",
    "print( f\"selectedRecord {selectedRecord} => {nbRecords[selectedRecord]} files\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedTimeStamp = newTimeStamp[selectedRecord]\n",
    "selectedBufferNumber = bufferNumber[selectedRecord]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logEkfEuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate euler data for all timeStamps\n",
    "roll_selection = np.interp( selectedTimeStamp, eulerNewTimestamps, roll )\n",
    "pitch_selection = np.interp( selectedTimeStamp, eulerNewTimestamps, pitch )\n",
    "yaw_selection = np.interp( selectedTimeStamp, eulerNewTimestamps, yaw )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logGpsPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "velNewTimestamps = gpsNewTimestamps\n",
    "\n",
    "def getInterpolatedGps( timeStamp ):\n",
    "    Lat_records    = np.interp( timeStamp, gpsNewTimestamps, Lat )\n",
    "    Long_records   = np.interp( timeStamp, gpsNewTimestamps, Long )\n",
    "    Alt_records    = np.interp( timeStamp, gpsNewTimestamps, Alt )\n",
    "    Vel_records    = np.interp( timeStamp, velNewTimestamps, Vel )\n",
    "    course_records = np.interp( timeStamp, velNewTimestamps, course )\n",
    "    return Lat_records, Long_records, Alt_records, Vel_records, course_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lat_Long_Alt_Vel_course = getInterpolatedGps( selectedTimeStamp )\n",
    "selectedEpsg = epsg.wgs84ToEpsg( (Lat_Long_Alt_Vel_course[1], Lat_Long_Alt_Vel_course[0]), epsg3xxx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logGpsVel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "velNewTimestamps = gpsNewTimestamps\n",
    "\n",
    "def getInterpolatedVel( timeStamp ):\n",
    "    velNorth_records = np.interp( timeStamp, gpsNewTimestamps, velNorth )\n",
    "    velEast_records  = np.interp( timeStamp, gpsNewTimestamps, velEast )\n",
    "    velDown_records  = np.interp( timeStamp, gpsNewTimestamps, velDown )\n",
    "    return velNorth_records, velEast_records, velDown_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vel_records = getInterpolatedVel( selectedTimeStamp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot navigation data and record periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = \"files {} to {}\".format( firstRecord, nbRecords[selectedRecord] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "for idx in range(nbHours):\n",
    "    ax.plot( x[idx], y[idx], label=hours[idx] )\n",
    "    \n",
    "addRemarkablePoints( ax )\n",
    "    \n",
    "ax.plot( selectedEpsg[0], selectedEpsg[1], \".r\", markeredgecolor='black', label=data_date[selectedRecord] )\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "title = epsgStr + \" \" + day\n",
    "ax.set_title(title)\n",
    "#ax.set_aspect('equal')\n",
    "fig.savefig( f\"{data_dir[selectedRecord]}/{title}.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# East-West s0  => s1  14_12_21\n",
    "# West-East s2  => s3  14_14_43\n",
    "# South-North s4 => s5 14_18_28\n",
    "# North-South s6 => s7 14_21_00\n",
    "xA, yA = s6_epsg\n",
    "xB, yB = s7_epsg\n",
    "JA = s6\n",
    "JB = s7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAB = (xB - xA) / ( (xB - xA)**2 + (yB - yA)**2 )**0.5\n",
    "yAB = (yB - yA) / ( (xB - xA)**2 + (yB - yA)**2 )**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit vectors\n",
    "ux = ( xAB, yAB )\n",
    "uy = ( -yAB, xAB )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sceneReferencePoint\n",
    "JA_epsg = epsg.wgs84ToEpsg( (JA[1], JA[0]), epsg3xxx )\n",
    "JB_epsg = epsg.wgs84ToEpsg( (JB[1], JB[0]), epsg3xxx )\n",
    "JAJB = ( (JA_epsg[0]+JB_epsg[0])/2,\n",
    "        (JA_epsg[1]+JB_epsg[1])/2 )\n",
    "shiftInY = 0\n",
    "sceneReferencePoint = JAJB[0] + shiftInY * uy[0], JAJB[1] + shiftInY * uy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_model = { \"trackModel\" : \"model(x, p) = p[1]*x + p[2]\",\n",
    "               \"ux\" : (ux[0], ux[1]),\n",
    "               \"uy\" : (uy[0], uy[1]),\n",
    "               \"origX\" : sceneReferencePoint[0],\n",
    "               \"origY\" : sceneReferencePoint[1]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackFilename = data_dir[selectedRecord] + \"/track_model.json\"\n",
    "with open( trackFilename, 'w' ) as f:\n",
    "    json.dump( track_model, f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_selection = np.interp( selectedTimeStamp, gpsNewTimestamps, gps_proj[0] )\n",
    "y_selection = np.interp( selectedTimeStamp, gpsNewTimestamps, gps_proj[1] )\n",
    "np.save( data_dir[selectedRecord] + \"/track_selection_proj\", np.stack( (x_selection, y_selection ), -1 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate navigation data for all ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rampNumber timeStamp x y z\n",
    "nbRecordToAdd = 10\n",
    "\n",
    "rampNumber = np.arange( rampsPerFile * ( nbRecords[selectedRecord] + nbRecordToAdd ) )\n",
    "\n",
    "rampNumber_ext = np.arange(nbRecords[selectedRecord] + nbRecordToAdd) * rampsPerFile\n",
    "\n",
    "lastDelta = selectedTimeStamp[-1] - selectedTimeStamp[-2]\n",
    "# there is a difference between the number of valid timestamps and the number of records\n",
    "diffValidTimestampsNbRecords = selectedTimeStamp.size - nbRecords[selectedRecord]\n",
    "addedTimestamps = np.arange( 1, nbRecordToAdd - diffValidTimestampsNbRecords + 1 ) * lastDelta\n",
    "print(\"lastDelta = {}\".format(lastDelta) )\n",
    "timeStamp_ext_a = np.concatenate( (selectedTimeStamp, \n",
    "                                 selectedTimeStamp[-1] + addedTimestamps ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestampsAllRamps = np.interp( rampNumber, rampNumber_ext, timeStamp_ext_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logGpsPos (a)\n",
    "Two options: numpy.interp vs scipy.interpolate.interp1d (with kind='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_x = np.interp( timestampsAllRamps, gpsNewTimestamps, gps_proj[0] )\n",
    "gps_y = np.interp( timestampsAllRamps, gpsNewTimestamps, gps_proj[1] )\n",
    "gps_z = np.interp( timestampsAllRamps, gpsNewTimestamps, Alt )\n",
    "xyz_proj_allRamps = np.stack( (rampNumber, timestampsAllRamps, \n",
    "                               gps_x, gps_y, gps_z), -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( data_dir[selectedRecord] + \"/rampNumber_timeStamp_xyz_gps_a\", xyz_proj_allRamps )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lla latitude longitude altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRamps_lat = np.interp( timestampsAllRamps, gpsNewTimestamps, Lat )\n",
    "allRamps_long = np.interp( timestampsAllRamps, gpsNewTimestamps, Long )\n",
    "allRamps_alt = np.interp( timestampsAllRamps, gpsNewTimestamps, Alt )\n",
    "latLongAlt_allRamps = np.stack( (rampNumber, timestampsAllRamps,\n",
    "                                 allRamps_lat, allRamps_long, allRamps_alt), -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( data_dir[selectedRecord] + \"/rampNumber_timeStamp_latLongAlt_gps_a\", latLongAlt_allRamps )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logEkfNav (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_x = np.interp( timestampsAllRamps, navNewTimestamps, nav_proj[0] )\n",
    "nav_y = np.interp( timestampsAllRamps, navNewTimestamps, nav_proj[1] )\n",
    "nav_z = np.interp( timestampsAllRamps, navNewTimestamps, nav_Alt )\n",
    "nav_u = np.interp( timestampsAllRamps, navNewTimestamps, nav_Undulation )\n",
    "nav_xyz_allRamps = np.stack( (rampNumber, timestampsAllRamps, \n",
    "                              nav_x, nav_y, nav_z), -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( data_dir[selectedRecord] + \"/rampNumber_timeStamp_xyz_nav_a\", nav_xyz_allRamps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_allRamps_lat = np.interp( timestampsAllRamps, navNewTimestamps, nav_Lat )\n",
    "nav_allRamps_long = np.interp( timestampsAllRamps, navNewTimestamps, nav_Long )\n",
    "nav_allRamps_alt = np.interp( timestampsAllRamps, navNewTimestamps, nav_Alt )\n",
    "nav_latLongAlt_allRamps = np.stack( (rampNumber, timestampsAllRamps, \n",
    "                              nav_allRamps_lat, nav_allRamps_long, nav_allRamps_alt), -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( data_dir[selectedRecord] + \"/rampNumber_timeStamp_latLongAlt_nav_a\", nav_latLongAlt_allRamps )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logGpsPos (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rampNumber timeStamp x y z\n",
    "\n",
    "timeStamp_ext_b = timeStamp_ext_a + params.rampPeriod / 2\n",
    "\n",
    "timeStamp = np.interp( rampNumber, rampNumber_ext, timeStamp_ext_b)\n",
    "x = np.interp( timeStamp, gpsNewTimestamps, gps_proj[0] )\n",
    "y = np.interp( timeStamp, gpsNewTimestamps, gps_proj[1] )\n",
    "z = np.interp( timeStamp, gpsNewTimestamps, Alt )\n",
    "xyz_proj_allRamps = np.stack( (rampNumber, timeStamp, x, y, z), -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( data_dir[selectedRecord] + \"/rampNumber_timeStamp_xyz_b\", xyz_proj_allRamps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
